{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['profit', 0.4203323657208688, 'aol', 0.29423265600460813, 'timewarn', 0.29423265600460813, 'sale', 0.2101661828604344, 'internet', 0.16813294628834752]], [['process', 0.5856898768280098, 'schedul', 0.48383076781444284, 'time', 0.3158380608969707, 'cpu', 0.20371821802713383, 'queue', 0.20371821802713383]], [['electron', 0.477559543114113, 'go', 0.3366403336706043, 'right', 0.20354996919617935, 'equal', 0.1957211242270955, 'get', 0.17223458931984403]]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os,glob\n",
    "import numpy as np\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse.csr import csr_matrix #need this if you want to save tfidf_matrix\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "#path is that of the current directory\n",
    "path = os.getcwd()\n",
    "#print(location)\n",
    "\n",
    "#empty list of corpus\n",
    "corpus = []\n",
    "\n",
    "fullData = []\n",
    "fullData2 = []\n",
    "#append each file with .txt extension to the corpus\n",
    "\n",
    "for filename in sorted(glob.glob(os.path.join(path, '*.txt'))):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "        #print (filename)\n",
    "        #print (len(text))\n",
    "        corpus.append(text)\n",
    "\n",
    "\n",
    "        \n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "port = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stem_words(doc):\n",
    "    return[port.stem(word) for word in analyzer(doc) if word not in stop_words]\n",
    "\n",
    "\n",
    "\n",
    "cv=CountVectorizer(analyzer=stem_words,stop_words = 'english',lowercase=True)\n",
    "\n",
    "# this steps generates word counts for the words in your docs\n",
    "word_count_vector=cv.fit_transform(corpus)\n",
    "\n",
    "word_count_vector.shape\n",
    "\n",
    "\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "\n",
    "count_vector=cv.transform(corpus)\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "\n",
    "\n",
    "feature_names = cv.get_feature_names()\n",
    "\n",
    "top5AllFiles = []\n",
    "\n",
    "\n",
    "#build dataframe of first document. Determined by the index od tf-idf_vector below\n",
    "\n",
    "corpusLength = len(corpus)\n",
    "\n",
    "for i in range(0,corpusLength):\n",
    "    #print(i)\n",
    "    df = pd.DataFrame(tf_idf_vector[i].T.todense(), index=feature_names, columns= [\"tfidf\"])\n",
    "    df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "    #get top 5 words\n",
    "    top5=df.nlargest(5, \"tfidf\")\n",
    "    #print(top5)\n",
    "    array = []\n",
    "    data1=[]\n",
    "    for i, j in top5.iterrows():\n",
    "        data1.append(i)\n",
    "        data1.append(j.tfidf)\n",
    "\n",
    "    #print(data1)\n",
    "    # open output file for writing\n",
    "    array.append(data1)\n",
    "    top5AllFiles.append(array)\n",
    "\n",
    "print(top5AllFiles)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
